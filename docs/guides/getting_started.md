# å¿«é€Ÿå¼€å§‹æŒ‡å—

æ¬¢è¿ä½¿ç”¨ Agioï¼æœ¬æŒ‡å—å°†å¸®åŠ©ä½ åœ¨ 5 åˆ†é’Ÿå†…åˆ›å»ºç¬¬ä¸€ä¸ª AI Agentã€‚

---

## ğŸ“¦ å®‰è£…

### ä½¿ç”¨ pip

```bash
pip install agio
```

### ä»æºç å®‰è£…

```bash
git clone https://github.com/yourusername/agio.git
cd agio
pip install -e .
```

### ä¾èµ–è¦æ±‚

- Python 3.9+
- OpenAI API Key (æˆ–å…¶ä»–æ”¯æŒçš„ LLM provider)

---

## ğŸš€ ç¬¬ä¸€ä¸ª Agentï¼ˆ30ç§’ï¼‰

åˆ›å»º `hello.py`:

```python
import asyncio
from agio.agent import Agent
from agio.models import OpenAIModel

async def main():
    # 1. åˆ›å»º Agent
    agent = Agent(
        model=OpenAIModel(name="gpt-4"),
        name="my_first_agent"
    )
    
    # 2. è¿è¡Œ
    async for chunk in agent.arun("Hello! Who are you?"):
        print(chunk, end="", flush=True)

if __name__ == "__main__":
    asyncio.run(main())
```

è¿è¡Œï¼š

```bash
export OPENAI_API_KEY="sk-..."
python hello.py
```

---

## ğŸ”§ æ·»åŠ å·¥å…·

Agents çš„çœŸæ­£å¨åŠ›åœ¨äºä½¿ç”¨å·¥å…·ã€‚è®©æˆ‘ä»¬æ·»åŠ ä¸€äº›ï¼š

```python
import asyncio
from agio.agent import Agent
from agio.models import OpenAIModel
from agio.tools import FunctionTool

# å®šä¹‰å·¥å…·å‡½æ•°
def get_weather(city: str) -> str:
    """Get the current weather for a city."""
    # è¿™é‡Œå¯ä»¥è°ƒç”¨çœŸå®çš„å¤©æ°” API
    return f"The weather in {city} is sunny, 25Â°C"

def calculate(expression: str) -> str:
    """Calculate a mathematical expression."""
    try:
        result = eval(expression)  # æ³¨æ„ï¼šç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨å®‰å…¨çš„è®¡ç®—åº“
        return f"{expression} = {result}"
    except Exception as e:
        return f"Error: {e}"

async def main():
    agent = Agent(
        model=OpenAIModel(name="gpt-4"),
        tools=[
            FunctionTool(get_weather),
            FunctionTool(calculate)
        ],
        name="tool_agent"
    )
    
    query = "What's the weather in Beijing? Also, what is 123 * 456?"
    
    async for chunk in agent.arun(query):
        print(chunk, end="", flush=True)

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ¯ ä½¿ç”¨äº‹ä»¶æµ API

è·å¾—æ›´ç²¾ç»†çš„æ§åˆ¶å’Œæ›´å¥½çš„ç”¨æˆ·ä½“éªŒï¼š

```python
import asyncio
from agio.agent import Agent
from agio.models import OpenAIModel
from agio.tools import FunctionTool
from agio.protocol.events import EventType

def search_web(query: str) -> str:
    """Search the web for information."""
    return f"Search results for: {query}"

async def main():
    agent = Agent(
        model=OpenAIModel(name="gpt-4"),
        tools=[FunctionTool(search_web)]
    )
    
    print("ğŸ¤– Agent: ", end="", flush=True)
    
    async for event in agent.arun_stream("Search for Python async programming"):
        match event.type:
            case EventType.TEXT_DELTA:
                # æ˜¾ç¤º AI è¿”å›çš„æ–‡æœ¬
                print(event.data["content"], end="", flush=True)
            
            case EventType.TOOL_CALL_STARTED:
                # æ˜¾ç¤ºå·¥å…·è°ƒç”¨
                tool_name = event.data["tool_name"]
                print(f"\n\nğŸ”§ Calling tool: {tool_name}...", flush=True)
            
            case EventType.TOOL_CALL_COMPLETED:
                # å·¥å…·å®Œæˆ
                print("âœ… Tool completed", flush=True)
                print("\nğŸ¤– Agent: ", end="", flush=True)
            
            case EventType.USAGE_UPDATE:
                # æ˜¾ç¤º token ä½¿ç”¨
                usage = event.data
                tokens = usage.get("total_tokens", 0)
                print(f"\n\nğŸ“Š Tokens used: {tokens}", flush=True)

if __name__ == "__main__":
    asyncio.run(main())
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
ğŸ¤– Agent: Let me search for information about Python async programming.

ğŸ”§ Calling tool: search_web...
âœ… Tool completed

ğŸ¤– Agent: Based on the search results, Python async programming...

ğŸ“Š Tokens used: 245
```

---

## ğŸ’¾ æ·»åŠ è®°å¿†

è®© Agent è®°ä½å¯¹è¯å†å²ï¼š

```python
import asyncio
from agio.agent import Agent
from agio.models import OpenAIModel
from agio.memory import SimpleMemory

async def main():
    agent = Agent(
        model=OpenAIModel(name="gpt-4"),
        memory=SimpleMemory(),  # æ·»åŠ è®°å¿†
        name="memory_agent"
    )
    
    # ç¬¬ä¸€è½®å¯¹è¯
    print("User: My name is Alice\n")
    async for chunk in agent.arun("My name is Alice", session_id="session_1"):
        print(chunk, end="", flush=True)
    
    print("\n\n---\n")
    
    # ç¬¬äºŒè½®å¯¹è¯ - Agent ä¼šè®°ä½åå­—
    print("User: What's my name?\n")
    async for chunk in agent.arun("What's my name?", session_id="session_1"):
        print(chunk, end="", flush=True)

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ“š æ·»åŠ çŸ¥è¯†åº“ï¼ˆRAGï¼‰

è®© Agent è®¿é—®ä½ çš„æ–‡æ¡£ï¼š

```python
import asyncio
from agio.agent import Agent
from agio.models import OpenAIModel
from agio.knowledge import VectorKnowledge

async def main():
    # åˆ›å»ºçŸ¥è¯†åº“
    knowledge = VectorKnowledge(
        collection_name="my_docs",
        embedding_model="text-embedding-3-small"
    )
    
    # æ·»åŠ æ–‡æ¡£ï¼ˆåªéœ€è¦åšä¸€æ¬¡ï¼‰
    await knowledge.add_documents([
        "Agio is a Python agent framework.",
        "Agio supports async operations natively.",
        "Agio has built-in observability features."
    ])
    
    # åˆ›å»º Agent
    agent = Agent(
        model=OpenAIModel(name="gpt-4"),
        knowledge=knowledge,
        name="rag_agent"
    )
    
    # æŸ¥è¯¢ - Agent ä¼šä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯
    async for chunk in agent.arun("What is Agio?"):
        print(chunk, end="", flush=True)

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ’¿ æŒä¹…åŒ–å’Œå†å²å›æ”¾

ä¿å­˜æ‰€æœ‰å¯¹è¯ï¼Œç¨åå›æ”¾ï¼š

```python
import asyncio
from agio.agent import Agent
from agio.models import OpenAIModel
from agio.db.repository import InMemoryRepository
from agio.protocol.events import EventType

async def main():
    # åˆ›å»º Repository
    repository = InMemoryRepository()
    
    # åˆ›å»º Agent
    agent = Agent(
        model=OpenAIModel(name="gpt-4"),
        repository=repository,  # å¯ç”¨æŒä¹…åŒ–
        name="persistent_agent"
    )
    
    # æ‰§è¡Œå¹¶è‡ªåŠ¨ä¿å­˜
    run_id = None
    async for event in agent.arun_stream("Hello!"):
        if event.type == EventType.RUN_STARTED:
            run_id = event.data["run_id"]
            print(f"Run ID: {run_id}\n")
        elif event.type == EventType.TEXT_DELTA:
            print(event.data["content"], end="", flush=True)
    
    print("\n\n--- Replay ---\n")
    
    # å›æ”¾å†å²
    async for event in agent.get_run_history(run_id):
        if event.type == EventType.TEXT_DELTA:
            print(event.data["content"], end="", flush=True)
    
    # åˆ—å‡ºæ‰€æœ‰ runs
    print("\n\n--- All Runs ---\n")
    runs = await agent.list_runs(limit=10)
    for run in runs:
        print(f"- {run.id}: {run.input_query[:50]}... ({run.status})")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ¨ Web é›†æˆç¤ºä¾‹

### FastAPI + SSE

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from agio.agent import Agent
from agio.models import OpenAIModel

app = FastAPI()
agent = Agent(model=OpenAIModel(name="gpt-4"))

@app.post("/chat")
async def chat(query: str):
    async def event_stream():
        async for event in agent.arun_stream(query):
            # å‘é€ Server-Sent Events
            yield f"data: {event.model_dump_json()}\n\n"
    
    return StreamingResponse(
        event_stream(), 
        media_type="text/event-stream"
    )
```

### Gradio UI

```python
import gradio as gr
from agio.agent import Agent
from agio.models import OpenAIModel

agent = Agent(model=OpenAIModel(name="gpt-4"))

async def chat(message, history):
    response = ""
    async for chunk in agent.arun(message):
        response += chunk
        yield response

demo = gr.ChatInterface(chat)
demo.launch()
```

---

## ğŸ” è°ƒè¯•å’Œå¯è§‚æµ‹æ€§

ä½¿ç”¨ Hooks å®ç°è‡ªå®šä¹‰é€»è¾‘ï¼š

```python
import asyncio
from agio.agent import Agent
from agio.models import OpenAIModel
from agio.agent.hooks.base import AgentHook

class DebugHook(AgentHook):
    async def on_run_start(self, run):
        print(f"ğŸš€ Run started: {run.id}")
    
    async def on_tool_start(self, run, step, tool_calls):
        for tc in tool_calls:
            print(f"ğŸ”§ Calling: {tc['name']}")
    
    async def on_run_end(self, run):
        print(f"âœ… Run completed in {run.metrics.duration:.2f}s")
        print(f"   Tokens: {run.metrics.total_tokens}")
        print(f"   Tools: {run.metrics.tool_calls_count}")

async def main():
    agent = Agent(
        model=OpenAIModel(name="gpt-4"),
        hooks=[DebugHook()],
        name="debug_agent"
    )
    
    async for chunk in agent.arun("Hello!"):
        print(chunk, end="", flush=True)

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ“ é…ç½®å’Œç¯å¢ƒå˜é‡

### ä½¿ç”¨ .env æ–‡ä»¶

åˆ›å»º `.env`:

```env
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_BASE_URL=https://api.openai.com/v1

# Deepseek
DEEPSEEK_API_KEY=sk-...

# æ•°æ®åº“
MONGODB_URI=mongodb://localhost:27017
```

### ä½¿ç”¨é…ç½®æ–‡ä»¶

```python
from agio.agent import Agent
from agio.models import OpenAIModel
from agio.runners.config import AgentRunConfig

# è‡ªå®šä¹‰é…ç½®
config = AgentRunConfig(
    max_steps=20,                    # æœ€å¤§æ‰§è¡Œæ­¥æ•°
    max_context_messages=50,         # æœ€å¤§ä¸Šä¸‹æ–‡æ¶ˆæ¯æ•°
    max_rag_docs=10,                 # æœ€å¤§ RAG æ–‡æ¡£æ•°
    enable_memory_update=True,       # å¯ç”¨è®°å¿†æ›´æ–°
)

agent = Agent(
    model=OpenAIModel(name="gpt-4", temperature=0.7),
    config=config
)
```

---

## ğŸ“ ä¸‹ä¸€æ­¥

- ğŸ“– é˜…è¯» [æ¶æ„æ–‡æ¡£](../docs/architecture/overview.md)
- ğŸ”§ æŸ¥çœ‹ [å®Œæ•´ç¤ºä¾‹](../examples/)
- ğŸ› ï¸ å­¦ä¹  [è‡ªå®šä¹‰æ‰©å±•](../docs/guides/custom_extensions.md)
- ğŸ¤ å‚ä¸ [è´¡çŒ®](../CONTRIBUTING.md)

---

## ğŸ’¡ å¸¸è§é—®é¢˜

### Q: Agio ä¸ LangChain æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

A: Agio ä¸“æ³¨äºï¼š
- ğŸš€ **å¼‚æ­¥åŸç”Ÿ** - å…¨é“¾è·¯å¼‚æ­¥ï¼Œå¤©ç„¶æ”¯æŒæµå¼
- ğŸ“Š **äº‹ä»¶é©±åŠ¨** - 15ç§äº‹ä»¶ç±»å‹ï¼Œå®Œæ•´çš„å¯è§‚æµ‹æ€§
- ğŸ—ï¸ **æ¶æ„æ¸…æ™°** - ä¸‰å±‚è®¾è®¡ï¼ŒèŒè´£åˆ†ç¦»
- ğŸ’¿ **å†å²å›æ”¾** - å®Œæ•´çš„äº‹ä»¶å­˜å‚¨å’Œå›æ”¾

### Q: æ”¯æŒå“ªäº› LLMï¼Ÿ

A: å½“å‰æ”¯æŒï¼š
- âœ… OpenAI (GPT-4, GPT-3.5)
- âœ… Deepseek
- â³ Anthropic Claude (è®¡åˆ’ä¸­)
- â³ Google Gemini (è®¡åˆ’ä¸­)
- âœ… ä»»ä½•å…¼å®¹ OpenAI API çš„æ¨¡å‹

### Q: å¦‚ä½•éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒï¼Ÿ

A: å‚è€ƒæˆ‘ä»¬çš„ [ç”Ÿäº§éƒ¨ç½²æŒ‡å—](../docs/guides/deployment.md)

---

**éœ€è¦å¸®åŠ©ï¼Ÿ** [æäº¤ Issue](https://github.com/yourusername/agio/issues) æˆ–åŠ å…¥æˆ‘ä»¬çš„ [Discord](https://discord.gg/agio)
