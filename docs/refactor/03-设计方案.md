# 三、设计方案：统一抽象设计 (Composite Pattern)

> **设计原则**：RunnableExecutor 只负责 Run 生命周期管理，**不侵入** `Runnable.run()` 签名
>
> **SOLID & KISS**：单一职责、最小化改动、保持现有接口稳定

## 3.1 核心洞察

**Agent 和 Workflow 不是两种物种，而是同一接口的两种实现**：

```
                    ┌─────────────┐
                    │  Runnable   │  ← 统一协议（签名不变）
                    │  Protocol   │
                    └──────┬──────┘
                           │
           ┌───────────────┴───────────────┐
           │                               │
    ┌──────┴──────┐                 ┌──────┴──────┐
    │   Agent     │                 │  Workflow   │
    │   (Leaf)    │                 │ (Composite) │
    │             │                 │             │
    │ 状态：Steps  │                 │ 状态：节点缓存│
    └─────────────┘                 └──────┬──────┘
                                           │
                              ┌────────────┼────────────┐
                              │            │            │
                         ┌────┴────┐ ┌─────┴─────┐ ┌────┴────┐
                         │ Agent A │ │ Workflow B │ │ Agent C │
                         └─────────┘ └───────────┘ └─────────┘
```

- **Agent (Leaf)**：原子节点，状态基于 Steps（对话历史）
- **Workflow (Composite)**：组合节点，状态基于节点输出缓存（WorkflowState）
- **RunnableExecutor 只引用 domain.protocol.Runnable。它绝对不引用 agio.agent.Agent 或 agio.workflow.base.BaseWorkflow**

## 3.2 方案 D 的关键决策

| 决策点 | 选择 | 原因 |
|--------|------|------|
| **Runnable.run() 签名** | **不修改** | Agent 不需要 `state` 参数，强制添加是噪音 |
| **状态管理** | **保持分离** | Agent 用 Steps，Workflow 用 WorkflowState，本质不同 |
| **RunnableExecutor 职责** | **只管 Run 生命周期** | 不侵入 Runnable 内部逻辑 |
| **Run 模型** | **统一为 Run** | 增加 `runnable_type` 区分 Agent/Workflow |
| **SessionStore 依赖** | **统一为构造函数注入** | 类型安全，显式依赖 |

## 3.3 Runnable 协议（微调：添加 runnable_type）

```python
@runtime_checkable
class Runnable(Protocol):
    """
    统一协议 - 核心签名保持不变。
    
    Agent 和 Workflow 各自管理自己的状态，不强制统一。
    """
    
    @property
    def id(self) -> str: ...
    
    @property
    def runnable_type(self) -> str:
        """
        返回 Runnable 类型标识。
        
        - Agent 返回 "agent"
        - Workflow 返回 "workflow"
        
        RunnableExecutor 通过此属性判断类型，
        避免 isinstance 或 hasattr(_nodes) 等反模式。
        """
        ...
    
    async def run(
        self,
        input: str,
        *,
        context: ExecutionContext,  # ← 不增加 state 参数
    ) -> RunOutput: ...
```

**实现示例**：

```python
class Agent:
    @property
    def runnable_type(self) -> str:
        return "agent"

class BaseWorkflow:
    @property
    def runnable_type(self) -> str:
        return "workflow"
```

## 3.4 RunnableExecutor：只负责 Run 生命周期

```python
class RunnableExecutor:
    """
    统一执行引擎 - 只负责 Run 生命周期管理。
    
    职责：
    1. 创建 Run 记录
    2. 管理 Run 状态 (RUNNING → COMPLETED/FAILED)
    3. 发射 Run 级别事件
    4. 保存 Run 到 SessionStore
    
    不负责：
    - 状态管理（由 Agent/Workflow 各自处理）
    - 修改 Runnable 内部逻辑
    """
    
    def __init__(self, store: SessionStore):
        self.store = store
    
    async def execute(
        self,
        runnable: Runnable,
        input: str,
        context: ExecutionContext,
    ) -> RunOutput:
        """
        统一执行入口 - 包装 Run 生命周期。
        
        流程：
        1. 创建 Run 记录
        2. 发射 RUN_STARTED 事件
        3. 委托给 runnable.run()（不修改签名）
        4. 更新 Run 状态
        5. 发射 RUN_COMPLETED/FAILED 事件
        6. 保存 Run
        """
        # 1. 创建 Run 记录
        run = Run(
            id=context.run_id,
            runnable_id=runnable.id,
            runnable_type=self._get_runnable_type(runnable),
            session_id=context.session_id,
            status=RunStatus.RUNNING,
            input_query=input,
            parent_run_id=context.parent_run_id,
            depth=context.depth,
            node_id=context.node_id,
        )
        run.metrics.start_time = time.time()
        
        # 2. 发射 RUN_STARTED 事件
        ef = EventFactory(context)
        await context.wire.write(ef.run_started(input))
        
        try:
            # 3. 委托执行（签名不变）
            result = await runnable.run(input, context=context)
            
            # 4. 更新 Run
            run.status = RunStatus.COMPLETED
            run.response_content = result.response
            run.metrics.end_time = time.time()
            run.metrics.duration = run.metrics.end_time - run.metrics.start_time
            run.metrics = result.metrics  # 使用返回的 metrics
            
            # 5. 发射 RUN_COMPLETED 事件
            await context.wire.write(ef.run_completed(result.response, result.metrics))
            
            # 6. 保存 Run
            if self.store:
                await self.store.save_run(run)
            
            return result
            
        except Exception as e:
            run.status = RunStatus.FAILED
            run.metrics.end_time = time.time()
            
            # 发射 RUN_FAILED 事件
            await context.wire.write(ef.run_failed(str(e)))
            
            if self.store:
                await self.store.save_run(run)
            raise
    
    def _get_runnable_type(self, runnable: Runnable) -> str:
        """
        判断 Runnable 类型。
        
        注意：不使用 isinstance 或 hasattr 检查具体类型，
        而是通过 Runnable protocol 的扩展属性来判断。
        """
        # 方案 A：在 Runnable protocol 中添加 runnable_type 属性
        if hasattr(runnable, 'runnable_type'):
            return runnable.runnable_type
        # 方案 B：默认为 agent（向后兼容）
        return "agent"
```

## 3.5 Agent 实现（保持现有逻辑）

```python
class Agent(Runnable):
    """
    原子 Runnable - 叶子节点。
    
    状态管理：基于 Steps（通过 session_store.get_steps 获取历史）
    执行逻辑：委托给 StepRunner → StepExecutor（保持不变）
    """
    
    def __init__(
        self,
        model: Model,
        tools: list[BaseTool] | None = None,
        session_store: SessionStore | None = None,  # ← 构造函数注入
        name: str = "agent",
        **kwargs,
    ):
        self._id = name
        self.model = model
        self.tools = tools or []
        self.session_store = session_store
        # ...
    
    async def run(
        self,
        input: str,
        *,
        context: ExecutionContext,  # ← 签名不变
    ) -> RunOutput:
        """执行 LLM Loop - 委托给 StepRunner"""
        # StepRunner 内部会：
        # 1. 创建 User Step
        # 2. 通过 build_context_from_steps() 构建上下文
        # 3. 调用 StepExecutor 执行 LLM Loop
        # 4. 保存 Steps
        # 注意：StepRunner 不再创建 AgentRun，由 RunnableExecutor 统一处理
        runner = StepRunner(
            agent=self,
            session_store=self.session_store,
        )
        return await runner.run(session, input, context.wire, context=context)
```

## 3.6 Workflow 实现（保持 WorkflowState）

```python
class BaseWorkflow(ABC, Runnable):
    """
    组合 Runnable - 容器节点。
    
    状态管理：基于 WorkflowState（节点输出缓存）
    执行逻辑：遍历节点，递归调用子 Runnable
    """
    
    def __init__(
        self,
        id: str,
        nodes: list[WorkflowNode],
        session_store: SessionStore | None = None,  # ✅ 构造函数注入（新增）
    ):
        self._id = id
        self._nodes = nodes
        self._session_store = session_store
        self._registry: dict[str, Runnable] = {}
    
    async def run(
        self,
        input: str,
        *,
        context: ExecutionContext,  # ← 签名不变
    ) -> RunOutput:
        """统一入口"""
        # 创建 WorkflowState（Workflow 专用）
        state = WorkflowState(
            session_id=context.session_id,
            workflow_id=self._id,  # ← 使用 workflow_id 而非 run_id
            store=self._session_store,
        )
        await state.load_from_history()
        
        # 创建 ContextResolver
        resolver = ContextResolver(
            session_id=context.session_id,
            workflow_id=self._id,
            store=self._session_store,
            state=state,
        )
        resolver.set_input(input)
        
        return await self._execute(input, context=context, state=state, resolver=resolver)


class PipelineWorkflow(BaseWorkflow):
    """顺序执行的 Workflow"""
    
    async def _execute(
        self,
        input: str,
        *,
        context: ExecutionContext,
        state: WorkflowState,       # ← Workflow 专用状态
        resolver: ContextResolver,
    ) -> RunOutput:
        result = input
        executor = RunnableExecutor(store=self._session_store)
        total_metrics = RunMetrics()
        start_time = time.time()
        
        for node in self._nodes:
            # 发射 NODE_STARTED 事件
            ef = EventFactory(context)
            await context.wire.write(ef.node_started(node_id=node.id))
            
            # 幂等性检查（Workflow 专用）
            if state.has_output(node.id):
                result = state.get_output(node.id)
                await context.wire.write(ef.node_skipped(node_id=node.id))
                continue
            
            # 解析输入
            node_input = await resolver.resolve_template(node.input_template)
            
            # 获取子 Runnable
            runnable = self._resolve_runnable(node.runnable)
            
            # 创建子上下文
            child_ctx = self._create_child_context(context, node)
            
            # 递归执行（通过 RunnableExecutor）
            output = await executor.execute(runnable, node_input, child_ctx)
            
            # 聚合 metrics
            total_metrics.aggregate(output.metrics)
            
            # 缓存结果
            result = output.response
            state.set_output(node.id, result)
            
            # 发射 NODE_COMPLETED 事件
            await context.wire.write(ef.node_completed(node_id=node.id))
        
        total_metrics.duration = time.time() - start_time
        total_metrics.nodes_executed = len(self._nodes)
        return RunOutput(response=result, metrics=total_metrics)
```

## 3.7 统一的 Run 模型

```python
class Run(BaseModel):
    """
    统一的执行记录 - 替代 AgentRun。
    
    通过 runnable_type 区分 Agent/Workflow。
    """
    id: str = Field(default_factory=lambda: str(uuid4()))
    runnable_id: str          # Agent ID 或 Workflow ID
    runnable_type: str        # "agent" | "workflow"
    session_id: str
    user_id: str | None = None
    
    status: RunStatus = RunStatus.STARTING
    input_query: str
    response_content: str | None = None
    
    metrics: RunMetrics = Field(default_factory=RunMetrics)
    
    # 层级信息
    parent_run_id: str | None = None
    depth: int = 0
    workflow_id: str | None = None  # 所属 Workflow
    node_id: str | None = None      # 所属节点
    
    created_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)
    
    # 可观测性
    trace_id: str | None = None
```

## 3.8 模块结构重组

```
agio/
├── domain/
│   ├── __init__.py
│   ├── models.py           # Step, Run, RunMetrics, StepMetrics
│   ├── protocol.py         # ✅ 新增：Runnable protocol, RunOutput
│   ├── events.py           # StepEvent, StepEventType
│   └── adapters.py
│
├── runtime/
│   ├── __init__.py
│   ├── runnable_executor.py  # ✅ 新增：RunnableExecutor
│   ├── runner.py             # StepRunner（移除 Run 管理）
│   ├── executor.py            # StepExecutor
│   ├── wire.py
│   ├── execution_context.py
│   └── ...
│
├── agent.py                    # Agent（Leaf Runnable，保持不变）
│
└── workflow/                   # Workflow 编排引擎
    ├── __init__.py
    ├── base.py                 # BaseWorkflow（新增 session_store 注入）
    ├── pipeline.py             # PipelineWorkflow
    ├── parallel.py             # ParallelWorkflow
    ├── loop.py                 # LoopWorkflow
    ├── node.py                 # WorkflowNode
    ├── state.py                # ✅ WorkflowState（从 runtime 移入）
    ├── resolver.py             # ✅ ContextResolver（从 runtime 移入）
    └── engine.py               # WorkflowEngine
```

## 3.9 StepRunner 重构：移除 Run 管理

```python
class StepRunner:
    """
    Agent 执行器 - 只负责 Step 管理。
    
    重构后移除的职责：
    - ❌ 创建 AgentRun（由 RunnableExecutor 统一处理）
    - ❌ 保存 AgentRun（由 RunnableExecutor 统一处理）
    - ❌ 发射 RUN_STARTED/RUN_COMPLETED 事件（由 RunnableExecutor 负责）
    
    保留的职责：
    - ✅ 创建 User Step
    - ✅ 构建 LLM 上下文
    - ✅ 调用 StepExecutor
    - ✅ 保存 Steps
    - ✅ 发射 Step 级别事件
    - ✅ 返回 RunOutput（包含 metrics）
    """
    
    async def run(
        self,
        session: AgentSession,
        query: str,
        wire: Wire,
        context: ExecutionContext,  # ← 使用 context.run_id
    ) -> RunOutput:
        # 不再创建 AgentRun
        # 不再发射 run_started/run_completed 事件
        
        # 使用外部传入的 run_id
        run_id = context.run_id
        
        # 1. 创建 User Step
        # 2. 构建上下文
        # 3. 执行 StepExecutor（发射 step 事件）
        # 4. 保存 Steps
        # 5. 返回 RunOutput（包含聚合的 metrics）
        ...
```

## 3.10 方案 D 的优势

### 1. 最小化改动

| 组件 | 改动程度 |
|------|----------|
| `Runnable.run()` 签名 | **不变** |
| `Agent` 内部逻辑 | **基本不变** |
| `WorkflowState` | **不变**（只移动位置） |
| `StepRunner` | **移除 Run 管理逻辑** |
| `Run` 模型 | **AgentRun 重命名 + 新增字段** |

### 2. 职责清晰

```
┌─────────────────────────────────────────────────────────────┐
│                   RunnableExecutor                          │
│           (只负责 Run 生命周期管理)                          │
├─────────────────────────────────────────────────────────────┤
│  1. 创建 Run 记录                                           │
│  2. 发射 Run 级别事件                                       │
│  3. 委托给 Runnable.run()                                   │
│  4. 更新 Run 状态                                           │
│  5. 保存 Run                                                │
└─────────────────────────────────────────────────────────────┘
                           │
           ┌───────────────┴───────────────┐
           │                               │
           ▼                               ▼
┌──────────────────────┐      ┌──────────────────────────┐
│       Agent          │      │        Workflow          │
│  (状态：Steps)       │      │  (状态：WorkflowState)   │
│                      │      │                          │
│  StepRunner          │      │  WorkflowState           │
│    └─ StepExecutor   │      │    └─ 节点输出缓存       │
│        └─ LLM Loop   │      │  ContextResolver         │
│                      │      │    └─ 模板解析           │
│  发射 Step 事件      │      │  发射 Node 事件          │
└──────────────────────┘      └──────────────────────────┘
```

### 3. 无限嵌套仍然支持

```
Workflow A
├── Node 1: Agent X           (Leaf)
├── Node 2: Workflow B        (Composite)
│   ├── Node 2.1: Workflow C  (Composite)
│   │   └── Node 2.1.1: Agent Y (Leaf)
│   └── Node 2.2: Agent Z     (Leaf)
└── Node 3: Agent W           (Leaf)
```

每个节点执行时，`RunnableExecutor` 创建对应的 `Run` 记录，形成完整的执行树。

### 4. 统一的 Run 追踪

所有执行（Agent 和 Workflow）都通过 `RunnableExecutor` 创建 `Run` 记录：
- 可以通过 `parent_run_id` 追溯执行链
- 可以通过 `runnable_type` 区分类型
- 前端可以用统一的组件渲染执行树

---

## 3.11 核心概念：Session、Run、Step 的关系

```
┌─────────────────────────────────────────────────────────────────┐
│                         Session                                  │
│  (会话容器 - 包含所有层级的数据)                                   │
│                                                                  │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │ Run (Workflow A)                                         │    │
│  │ runnable_type: "workflow"                                │    │
│  │                                                          │    │
│  │  ┌─────────────────────┐  ┌─────────────────────┐       │    │
│  │  │ Run (Agent X)       │  │ Run (Agent Y)       │       │    │
│  │  │ parent_run_id: A    │  │ parent_run_id: A    │       │    │
│  │  │ runnable_type: agent│  │ runnable_type: agent│       │    │
│  │  │                     │  │                     │       │    │
│  │  │ Steps:              │  │ Steps:              │       │    │
│  │  │ - user (seq=0)      │  │ - user (seq=3)      │       │    │
│  │  │ - assistant (seq=1) │  │ - assistant (seq=4) │       │    │
│  │  │ - tool (seq=2)      │  │ - tool (seq=5)      │       │    │
│  │  └─────────────────────┘  └─────────────────────┘       │    │
│  └─────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────┘
```

**核心定义**：

| 概念 | 定义 | 说明 |
|------|------|------|
| **Session** | 会话容器 | 包含所有层级的 Runs 和 Steps |
| **Run** | 一次 Runnable 执行 | Agent 执行或 Workflow 执行，通过 `parent_run_id` 形成树结构 |
| **Step** | 执行的原子单元 | user/assistant/tool 消息，属于 Session，由 Agent 产生 |

**关键点**：
- **Session 是扁平的**：所有 Steps 都直接属于 Session，sequence 全局递增
- **Run 是树状的**：通过 `parent_run_id` 形成层级关系
- **Step 归属于 Session**：不是归属于 Run，Run 只是执行记录
- **Workflow 本质是多个 Agent**：Workflow 不直接产生 Step，而是通过内部的 Agent 产生

---

## 3.12 Workflow 类型的 Step 处理设计

### 3.12.1 PipelineWorkflow（顺序执行）

**Step seq 策略**：全局递增，无冲突

```
Session: sid-123
├── Step seq=1, role=user, node_id=null          (顶层输入)
├── Step seq=2, role=user, node_id="node_A"      (Agent A 的输入)
├── Step seq=3, role=assistant, node_id="node_A" (Agent A 的输出)
├── Step seq=4, role=tool, node_id="node_A"      (Agent A 调用的工具)
├── Step seq=5, role=assistant, node_id="node_A" (Agent A 最终输出)
├── Step seq=6, role=user, node_id="node_B"      (Agent B 的输入)
├── Step seq=7, role=assistant, node_id="node_B" (Agent B 的输出)
└── ...
```

### 3.12.2 ParallelWorkflow（并行执行）

**问题**：多个 Agent 并行执行时，seq 如何处理？

**策略**：**预分配 seq 区间 + branch_key 标识**

```
Session: sid-123
                          ┌─────────────────────────────────────┐
                          │  ParallelWorkflow 开始执行           │
                          │  预分配 seq 区间:                    │
                          │  - Branch A: seq 100-199            │
                          │  - Branch B: seq 200-299            │
                          │  - Branch C: seq 300-399            │
                          └─────────────────────────────────────┘
                                          │
          ┌───────────────────────────────┼───────────────────────────────┐
          ▼                               ▼                               ▼
┌─────────────────┐             ┌─────────────────┐             ┌─────────────────┐
│  Branch A       │             │  Branch B       │             │  Branch C       │
│  branch_key="A" │             │  branch_key="B" │             │  branch_key="C" │
│                 │             │                 │             │                 │
│ seq=100 user    │             │ seq=200 user    │             │ seq=300 user    │
│ seq=101 assistant│            │ seq=201 assistant│            │ seq=301 assistant│
│ seq=102 tool    │             │ seq=202 tool    │             │                 │
│ seq=103 assistant│            │                 │             │                 │
└─────────────────┘             └─────────────────┘             └─────────────────┘
```

**实现方案**：

```python
class ParallelWorkflow(BaseWorkflow):
    SEQ_INTERVAL = 100  # 每个分支预留的 seq 区间大小

    async def _execute(self, input: str, *, context: ExecutionContext) -> RunOutput:
        # 获取当前 session 的 max_seq
        current_max_seq = await self._get_session_max_seq(context.session_id)
        
        # 为每个分支预分配 seq 起始值
        branches = self.nodes
        branch_seq_starts = {
            branch.id: current_max_seq + 1 + i * self.SEQ_INTERVAL
            for i, branch in enumerate(branches)
        }
        
        async def execute_branch(branch: WorkflowNode) -> BranchResult:
            child_ctx = self._create_child_context(context, branch)
            # 传递预分配的 seq 起始值
            child_ctx = child_ctx.with_metadata(
                branch_key=branch.id,
                seq_start=branch_seq_starts[branch.id],
            )
            return await runnable.run(node_input, context=child_ctx)
        
        # 并行执行
        results = await asyncio.gather(*[execute_branch(b) for b in branches])
```

**Step 模型扩展**：

```python
class Step(BaseModel):
    # ... 现有字段 ...
    branch_key: str | None = None  # 分支标识（用于并行执行）
```

**查询时排序规则**：
1. 先按 `branch_key` 分组（无 branch_key 的排前面）
2. 组内按 `sequence` 排序
3. 或直接按 `created_at` 时间戳排序

### 3.12.3 LoopWorkflow（循环执行）

**问题**：如何区分不同迭代的 Step？如何表示循环次数？

**策略**：**iteration 字段 + 复合 node_id**

```
Session: sid-123
├── Step seq=1, node_id="node_A", iteration=1     (第1轮 Agent A)
├── Step seq=2, node_id="node_A", iteration=1
├── Step seq=3, node_id="node_B", iteration=1     (第1轮 Agent B)
├── Step seq=4, node_id="node_B", iteration=1
├── Step seq=5, node_id="node_A", iteration=2     (第2轮 Agent A)
├── Step seq=6, node_id="node_A", iteration=2
├── Step seq=7, node_id="node_B", iteration=2     (第2轮 Agent B)
└── ...
```

**Step 模型扩展**：

```python
class Step(BaseModel):
    # ... 现有字段 ...
    iteration: int | None = None  # 循环迭代次数（从 1 开始）
```

**ExecutionContext 扩展**：

```python
class ExecutionContext:
    # ... 现有字段 ...
    iteration: int | None = None  # 当前循环迭代
    
    def with_iteration(self, iteration: int) -> "ExecutionContext":
        """创建带有迭代信息的新上下文"""
        return ExecutionContext(
            ...,
            iteration=iteration,
        )
```

**LoopWorkflow 实现**：

```python
class LoopWorkflow(BaseWorkflow):
    async def _execute(self, input: str, *, context: ExecutionContext) -> RunOutput:
        iteration = 0
        while iteration < self.max_iterations:
            iteration += 1
            
            for node in self.nodes:
                # 创建带迭代信息的子上下文
                child_ctx = self._create_child_context(context, node)
                child_ctx = child_ctx.with_iteration(iteration)
                
                result = await runnable.run(node_input, context=child_ctx)
            
            # 检查退出条件
            if not self._evaluate_condition():
                break
```

**WorkflowState 幂等性**：

LoopWorkflow 的幂等性键需要包含 iteration：

```python
def get_output_key(node_id: str, iteration: int | None = None) -> str:
    """生成幂等性检查的键"""
    if iteration:
        return f"{node_id}:iter_{iteration}"
    return node_id
```

---

## 3.13 Fork 和 Resume 统一设计

### 3.13.1 核心洞察

Workflow 执行时，所有 Agent 产生的 Steps 都在同一个 Session 中，且每个 Step 都有 `node_id` 标记。

**结论**：Fork/Resume **统一基于 Step sequence**，无需区分 Agent 和 Workflow。

### 3.13.2 统一的 Fork API

```python
# 统一的 Fork API - 保持现有设计，基于 Step sequence
POST /sessions/{session_id}/fork
{
    "sequence": 5,              # Fork 到哪个 Step
    "content": "...",           # 可选：修改内容
    "tool_calls": [...]         # 可选：修改 tool_calls
}

# 统一的 Resume API
POST /sessions/{session_id}/resume
{
    "runnable_id": "..."        # Agent ID 或 Workflow ID
}
```

### 3.13.3 各 Workflow 类型的 Fork/Resume 行为

#### PipelineWorkflow

| 操作 | 行为 |
|------|------|
| **Fork** | 复制 sequence ≤ N 的 Steps 到新 Session |
| **Resume** | WorkflowState 从 Steps 重建 node_id→output 缓存，跳过已完成节点 |

**示例**：

```
原 Session:
├── seq=1, node_id="node_A" ← Fork 到这里
├── seq=2, node_id="node_A"
├── seq=3, node_id="node_B" (被截断)
└── seq=4, node_id="node_B" (被截断)

新 Session (Fork 后):
├── seq=1, node_id="node_A" (复制)
├── seq=2, node_id="node_A" (复制)
└── (Resume 时从 node_B 继续)
```

#### ParallelWorkflow

| 操作 | 行为 |
|------|------|
| **Fork** | 复制 sequence ≤ N 的 Steps，保留 branch_key |
| **Resume** | 检查每个 branch 是否已完成，只重新执行未完成的分支 |

**关键问题**：Fork 到并行分支中间时如何处理？

**策略**：**分支级别原子性** - Fork 只能到分支边界

```
原 Session (ParallelWorkflow 执行到一半):
├── seq=100, branch_key="A", node_id="branch_A" ✓ 完成
├── seq=101, branch_key="A", node_id="branch_A" ✓ 完成
├── seq=200, branch_key="B", node_id="branch_B" ← 执行到这里失败
└── seq=300, branch_key="C", node_id="branch_C" (未开始)

Resume 后:
- Branch A: 跳过（已完成）
- Branch B: 重新执行（部分完成视为未完成）
- Branch C: 执行
```

**WorkflowState 分支检查**：

```python
class WorkflowState:
    def is_branch_completed(self, branch_id: str) -> bool:
        """检查分支是否完全完成"""
        return self.has_output(branch_id)  # 只有最终输出被缓存才算完成
```

#### LoopWorkflow

| 操作 | 行为 |
|------|------|
| **Fork** | 复制 sequence ≤ N 的 Steps，保留 iteration 信息 |
| **Resume** | 从当前 iteration 继续，跳过已完成的节点 |

**关键问题**：Fork 到某个迭代中间时如何处理？

**策略**：**迭代级别原子性** - Fork 后从该迭代的第一个节点重新开始

```
原 Session (LoopWorkflow 执行到第2轮中间):
├── seq=1, iteration=1, node_id="node_A" ✓
├── seq=2, iteration=1, node_id="node_B" ✓
├── seq=3, iteration=2, node_id="node_A" ← Fork 到这里
├── seq=4, iteration=2, node_id="node_B" (被截断)

新 Session (Fork 后):
├── seq=1, iteration=1, node_id="node_A" (复制)
├── seq=2, iteration=1, node_id="node_B" (复制)
├── seq=3, iteration=2, node_id="node_A" (复制)
└── (Resume 时从 iteration=2, node_B 继续)
```

**WorkflowState 迭代检查**：

```python
class WorkflowState:
    async def load_from_history(self) -> None:
        # 按 workflow_id + session_id 查询
        steps = await self._store.get_steps(
            session_id=self.session_id,
            workflow_id=self.workflow_id,
            role="assistant",
            has_node_id=True,
        )
        
        for step in steps:
            key = self._get_output_key(step.node_id, step.iteration)
            self._outputs[key] = step.content or ""
    
    def _get_output_key(self, node_id: str, iteration: int | None) -> str:
        if iteration:
            return f"{node_id}:iter_{iteration}"
        return node_id
```

### 3.13.4 Agent vs Workflow Resume 对比

| 维度 | Agent Resume | Workflow Resume |
|------|-------------|-----------------|
| **触发场景** | 最后 Step 是有 tool_calls 的 assistant | 需要从某个节点继续 |
| **恢复机制** | `resume_from_step()` 处理 pending tool_calls | 重新执行，`WorkflowState` 跳过已完成节点 |
| **状态来源** | Steps 本身就是状态 | Steps 中带 `node_id` 的记录 |

---

## 3.14 Metrics 分层聚合体系

### 3.14.1 三层 Metrics 结构

```
┌─────────────────────────────────────────────────────────────────┐
│                   Session Metrics (L3)                           │
│  (查询时聚合，不持久化)                                            │
│  total_runs, total_duration, total_tokens                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │                    Run Metrics (L2)                       │   │
│  │  (持久化到 Run 记录)                                       │   │
│  │  duration, total_tokens, steps_count, nodes_executed      │   │
│  │                                                           │   │
│  │  ┌─────────────────────────────────────────────────────┐  │   │
│  │  │                 Step Metrics (L1)                    │  │   │
│  │  │  (持久化到 Step 记录，扁平化结构)                       │  │   │
│  │  │                                                      │  │   │
│  │  │  # LLM 指标（assistant step）                        │  │   │
│  │  │  input_tokens, output_tokens, cache_tokens           │  │   │
│  │  │  duration_ms, first_token_latency_ms                 │  │   │
│  │  │  model_name, provider                                │  │   │
│  │  │                                                      │  │   │
│  │  │  # Tool 指标（tool step）                            │  │   │
│  │  │  tool_exec_time_ms, tool_name                        │  │   │
│  │  │  tool_success, tool_error                            │  │   │
│  │  └─────────────────────────────────────────────────────┘  │   │
│  └──────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
```

### 3.14.2 聚合策略：Sequential vs Parallel

| 指标 | 顺序执行 (sum) | 并行执行 (parallel) |
|------|---------------|---------------------|
| `duration` | sum(children) | **max(children)** |
| `first_token_latency` | 取第一个 | **min(children)** |
| `*_tokens` | sum(children) | sum(children) |
| `*_count` | sum(children) | sum(children) |

### 3.14.3 RunMetrics 统一定义（含 merge 方法）

```python
class RunMetrics(BaseModel):
    """
    Run 级别指标 - 聚合一次 Runnable 执行的所有 Steps。
    
    统一替代原 AgentRunMetrics 和 workflow/protocol.py 中的 RunMetrics。
    """
    # 时间
    start_time: float = 0.0
    end_time: float = 0.0
    duration: float = 0.0  # seconds
    
    # Token 聚合
    total_tokens: int = 0
    prompt_tokens: int = 0
    completion_tokens: int = 0
    cache_tokens: int = 0
    
    # 执行统计
    llm_calls_count: int = 0
    steps_count: int = 0
    tool_calls_count: int = 0
    tool_errors_count: int = 0
    
    # 延迟
    first_token_latency_ms: float | None = None
    response_latency: float | None = None
    
    # Workflow 专用
    nodes_executed: int | None = None
    iterations: int | None = None
    branches_executed: int | None = None  # ParallelWorkflow
    
    def merge(
        self, 
        other: "RunMetrics", 
        mode: Literal["sequential", "parallel"] = "sequential"
    ) -> None:
        """
        合并另一个 RunMetrics。
        
        Args:
            other: 要合并的指标
            mode: 合并模式
                - "sequential": 顺序执行，duration 累加
                - "parallel": 并行执行，duration 取 max
        """
        # Token 指标：始终累加
        self.total_tokens += other.total_tokens
        self.prompt_tokens += other.prompt_tokens
        self.completion_tokens += other.completion_tokens
        self.cache_tokens += other.cache_tokens
        
        # 执行统计：始终累加
        self.llm_calls_count += other.llm_calls_count
        self.steps_count += other.steps_count
        self.tool_calls_count += other.tool_calls_count
        self.tool_errors_count += other.tool_errors_count
        
        # Duration 和延迟：根据模式处理
        if mode == "sequential":
            self.duration += other.duration
            # first_token_latency 取第一个非空值
            if self.first_token_latency_ms is None:
                self.first_token_latency_ms = other.first_token_latency_ms
        else:  # parallel
            self.duration = max(self.duration, other.duration)
            # first_token_latency 取最小值（最快响应的分支）
            if other.first_token_latency_ms is not None:
                if self.first_token_latency_ms is None:
                    self.first_token_latency_ms = other.first_token_latency_ms
                else:
                    self.first_token_latency_ms = min(
                        self.first_token_latency_ms,
                        other.first_token_latency_ms
                    )
        
        # Workflow 专用字段：累加
        if other.nodes_executed:
            self.nodes_executed = (self.nodes_executed or 0) + other.nodes_executed
        if other.iterations:
            self.iterations = (self.iterations or 0) + other.iterations
        if other.branches_executed:
            self.branches_executed = (self.branches_executed or 0) + other.branches_executed
```

### 3.14.4 各 Workflow 类型的 Metrics 聚合

#### PipelineWorkflow

```python
class PipelineWorkflow(BaseWorkflow):
    async def _execute(self, ...) -> RunOutput:
        total_metrics = RunMetrics()
        start_time = time.time()
        
        for node in self._nodes:
            output = await executor.execute(runnable, node_input, child_ctx)
            # 顺序执行：mode="sequential"
            total_metrics.merge(output.metrics, mode="sequential")
        
        total_metrics.duration = time.time() - start_time
        total_metrics.nodes_executed = len(self._nodes)
        return RunOutput(response=result, metrics=total_metrics)
```

#### ParallelWorkflow

```python
class ParallelWorkflow(BaseWorkflow):
    async def _execute(self, ...) -> RunOutput:
        start_time = time.time()
        
        # 并行执行所有分支
        results = await asyncio.gather(*tasks)
        
        # 聚合 metrics：mode="parallel"
        total_metrics = RunMetrics()
        for result in results:
            if result.metrics:
                total_metrics.merge(result.metrics, mode="parallel")
        
        # 最终 duration 是整个并行执行的挂钟时间
        total_metrics.duration = time.time() - start_time
        total_metrics.branches_executed = len(self._nodes)
        return RunOutput(response=final_response, metrics=total_metrics)
```

#### LoopWorkflow

```python
class LoopWorkflow(BaseWorkflow):
    async def _execute(self, ...) -> RunOutput:
        total_metrics = RunMetrics()
        start_time = time.time()
        iteration = 0
        
        while iteration < self.max_iterations:
            iteration += 1
            iteration_metrics = RunMetrics()
            
            for node in self.nodes:
                output = await runnable.run(node_input, context=child_ctx)
                # 单次迭代内：顺序执行
                iteration_metrics.merge(output.metrics, mode="sequential")
            
            # 迭代之间：顺序执行
            total_metrics.merge(iteration_metrics, mode="sequential")
            
            if not self._evaluate_condition():
                break
        
        total_metrics.duration = time.time() - start_time
        total_metrics.iterations = iteration
        return RunOutput(response=final_output, metrics=total_metrics)
```

---

## 3.15 事件发射职责划分

### 三层事件模型

| 层级 | 事件类型 | 责任方 |
|------|----------|--------|
| **Run 层** | `RUN_STARTED`, `RUN_COMPLETED`, `RUN_FAILED` | `RunnableExecutor` |
| **Node 层** | `NODE_STARTED`, `NODE_COMPLETED`, `NODE_SKIPPED`, `BRANCH_STARTED`, `BRANCH_COMPLETED`, `ITERATION_STARTED` | `Workflow._execute()` |
| **Step 层** | `STEP_STARTED`, `STEP_DELTA`, `STEP_COMPLETED` | `StepRunner` / `StepExecutor` |

### 职责划分后的代码结构

```python
# RunnableExecutor - 只发射 Run 级别事件
class RunnableExecutor:
    async def execute(self, runnable, input, context) -> RunOutput:
        ef = EventFactory(context)
        await context.wire.write(ef.run_started(input))
        
        try:
            result = await runnable.run(input, context=context)
            await context.wire.write(ef.run_completed(result.response, result.metrics))
            return result
        except Exception as e:
            await context.wire.write(ef.run_failed(str(e)))
            raise

# StepRunner - 只发射 Step 级别事件（移除 run_started/run_completed）
class StepRunner:
    async def run(self, ...):
        # 不再发射 run_started
        # 只发射 step 事件
        async for event in executor.execute(...):
            await wire.write(event)  # step_delta, step_completed
        # 不再发射 run_completed
        return RunOutput(...)

# Workflow - 只发射 Node 级别事件
class PipelineWorkflow:
    async def _execute(self, ...):
        # 不再发射 run_started（由 RunnableExecutor 负责）
        for node in self._nodes:
            await wire.write(ef.node_started(node_id=node.id))
            result = await runnable.run(...)  # 内部会触发 Step 事件
            await wire.write(ef.node_completed(node_id=node.id))
        # 不再发射 run_completed（由 RunnableExecutor 负责）
        return RunOutput(...)
```

---

## 3.16 WorkflowState 查询优化

### 问题：run_id 查询在 Fork+Resume 场景失效

```
原 Session (sid-A):
├── Run-1 (run_id=xxx)
│   ├── Step seq=1, run_id=xxx, node_id="node_A"
│   └── Step seq=2, run_id=xxx, node_id="node_B"

Fork 到 Step seq=1 → 新 Session (sid-B):
├── Step seq=1, run_id=xxx, node_id="node_A"  ← 复制的，run_id 保持不变

Resume 新 Session:
├── 创建新 Run-2 (run_id=yyy)  ← 新的 run_id
├── WorkflowState(run_id=yyy).load_from_history()
│   └── 按 run_id=yyy 查询 → 找不到任何历史 Step！❌
```

### 解决方案：按 workflow_id + session_id 查询

```python
class WorkflowState:
    def __init__(
        self,
        session_id: str,
        workflow_id: str,  # ✅ 替代 run_id
        store: "SessionStore",
    ):
        self.session_id = session_id
        self.workflow_id = workflow_id
        self._store = store
        self._outputs: Dict[str, str] = {}

    async def load_from_history(self) -> None:
        # ✅ 按 workflow_id + session_id 查询
        # ✅ 只加载有 node_id 的 assistant steps
        steps = await self._store.get_steps(
            session_id=self.session_id,
            workflow_id=self.workflow_id,
            role="assistant",
            has_node_id=True,
        )
        
        for step in steps:
            key = self._get_output_key(step.node_id, step.iteration)
            self._outputs[key] = step.content or ""
```
