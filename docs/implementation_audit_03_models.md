# å®ç°å®¡è®¡ - Model å±‚

## 2. Model å®ç°æ€»ä½“è¯„ä¼°

**å®Œæˆåº¦**: âš ï¸ 40%  
**çŠ¶æ€**: ğŸŸ¡ éƒ¨åˆ†å®ç°

---

## âœ… å·²å®ç°åŠŸèƒ½

### 2.1 OpenAI Model

#### å®ç°ä½ç½®
- ğŸ“ `agio/models/openai.py`
- ğŸ“ 162 è¡Œä»£ç 

#### åŠŸèƒ½å®Œæ•´åº¦: âœ… 95%

**å·²å®ç°ç‰¹æ€§**:
- âœ… å®Œæ•´çš„ OpenAI API é›†æˆ
- âœ… æµå¼è¾“å‡ºæ”¯æŒ (`arun_stream`)
- âœ… å·¥å…·è°ƒç”¨æ”¯æŒ (Function Calling)
- âœ… é‡è¯•æœºåˆ¶ (`@retry_async`)
- âœ… ç¯å¢ƒå˜é‡é…ç½®
  - `OPENAI_API_KEY`
  - `OPENAI_BASE_URL`
- âœ… è‡ªå®šä¹‰ base_url æ”¯æŒ
- âœ… å®Œæ•´çš„å‚æ•°æ”¯æŒ:
  - temperature
  - max_tokens
  - top_p
  - frequency_penalty
  - presence_penalty

**ä»£ç ç¤ºä¾‹**:
```python
model = OpenAIModel(
    id="openai/gpt-4o-mini",
    name="gpt-4o-mini",
    api_key="sk-xxx",
    temperature=0.7
)

messages = [
    {"role": "system", "content": "You are helpful."},
    {"role": "user", "content": "Hello!"}
]

async for chunk in model.arun_stream(messages):
    if chunk.content:
        print(chunk.content, end="")
```

---

### 2.2 DeepSeek Model

#### å®ç°ä½ç½®
- ğŸ“ `agio/models/deepseek.py`
- ğŸ“ 67 è¡Œä»£ç 

#### åŠŸèƒ½å®Œæ•´åº¦: âœ… 80%

**å·²å®ç°ç‰¹æ€§**:
- âœ… åŸºäº OpenAI å…¼å®¹ API
- âœ… ç»§æ‰¿ OpenAIModel
- âœ… è‡ªå®šä¹‰ base_url
- âœ… ç¯å¢ƒå˜é‡æ”¯æŒ (`DEEPSEEK_API_KEY`)

**å®ç°æ–¹å¼**:
```python
class DeepSeekModel(OpenAIModel):
    """DeepSeek Model - OpenAI å…¼å®¹ API"""
    
    def model_post_init(self, __context) -> None:
        # è®¾ç½® DeepSeek API endpoint
        if not self.base_url:
            self.base_url = "https://api.deepseek.com/v1"
        
        # ä½¿ç”¨ DeepSeek API Key
        if not self.api_key:
            self.api_key = os.getenv("DEEPSEEK_API_KEY")
        
        super().model_post_init(__context)
```

---

## âŒ ç¼ºå¤±åŠŸèƒ½

### 3.1 Anthropic (Claude) Model

#### çŠ¶æ€: âŒ å®Œå…¨ç¼ºå¤±

**å½±å“**:
- é…ç½®æ–‡ä»¶ `configs/models/claude.yaml` å­˜åœ¨ä½†æ— æ³•ä½¿ç”¨
- Factory ä¸æ”¯æŒ anthropic provider
- ç”¨æˆ·æ— æ³•ä½¿ç”¨ Claude æ¨¡å‹

**éœ€è¦å®ç°**:
- ğŸ“ åˆ›å»º `agio/models/anthropic.py`
- é›†æˆ Anthropic Python SDK
- å®ç° `AnthropicModel` ç±»

**å‚è€ƒå®ç°ç»“æ„**:
```python
# agio/models/anthropic.py

from anthropic import AsyncAnthropic
from agio.models.base import Model, StreamChunk

class AnthropicModel(Model):
    """Anthropic Claude Model"""
    
    api_key: SecretStr | None = None
    client: AsyncAnthropic | None = None
    
    # Claude specific parameters
    max_tokens_to_sample: int = 4096
    
    def model_post_init(self, __context) -> None:
        # Initialize Anthropic client
        api_key = self.api_key or os.getenv("ANTHROPIC_API_KEY")
        self.client = AsyncAnthropic(api_key=api_key)
    
    async def arun_stream(
        self,
        messages: list[dict],
        tools: list[dict] | None = None
    ) -> AsyncIterator[StreamChunk]:
        # Convert messages to Anthropic format
        # Call Anthropic API
        # Convert to StreamChunk
        pass
```

**é…ç½®æ–‡ä»¶å·²å­˜åœ¨**:
```yaml
# configs/models/claude.yaml
type: model
name: claude
description: "Anthropic Claude 3 Opus"
provider: anthropic  # âŒ Factory ä¸æ”¯æŒ
model: claude-3-opus-20240229
api_key: ${ANTHROPIC_API_KEY}
temperature: 0.7
max_tokens: 4096
```

---

### 3.2 å…¶ä»– Provider æ”¯æŒ

#### Google (Gemini)
- çŠ¶æ€: âŒ æœªå®ç°
- éœ€æ±‚: æ”¯æŒ Gemini Pro, Gemini Ultra

#### Azure OpenAI
- çŠ¶æ€: âŒ æœªå®ç°
- éœ€æ±‚: æ”¯æŒ Azure éƒ¨ç½²çš„ OpenAI æ¨¡å‹

#### Cohere
- çŠ¶æ€: âŒ æœªå®ç°
- éœ€æ±‚: æ”¯æŒ Cohere Command ç³»åˆ—

#### Hugging Face
- çŠ¶æ€: âŒ æœªå®ç°
- éœ€æ±‚: æ”¯æŒ HF Inference API

---

### 3.3 Model åŠŸèƒ½å¢å¼º

#### æ‰¹é‡å¤„ç†
- çŠ¶æ€: âŒ æœªå®ç°
- éœ€æ±‚: æ”¯æŒæ‰¹é‡æ¶ˆæ¯å¤„ç†

#### ç¼“å­˜æ”¯æŒ
- çŠ¶æ€: âŒ æœªå®ç°
- éœ€æ±‚: å“åº”ç¼“å­˜ï¼Œå‡å°‘ API è°ƒç”¨

#### æˆæœ¬è¿½è¸ª
- çŠ¶æ€: âŒ æœªå®ç°
- éœ€æ±‚: è¿½è¸ª token ä½¿ç”¨å’Œæˆæœ¬

#### é€Ÿç‡é™åˆ¶
- çŠ¶æ€: âŒ æœªå®ç°
- éœ€æ±‚: è‡ªåŠ¨é€Ÿç‡é™åˆ¶å’Œé˜Ÿåˆ—

---

## ğŸ¯ ä¼˜å…ˆçº§å»ºè®®

### ğŸ”´ é«˜ä¼˜å…ˆçº§

1. **å®ç° Anthropic Model**
   - åˆ›å»º `agio/models/anthropic.py`
   - é›†æˆ Anthropic SDK
   - æ›´æ–° Factory provider_map
   - æµ‹è¯• Claude é…ç½®åŠ è½½

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§

2. **æ·»åŠ  Azure OpenAI æ”¯æŒ**
   - æ”¯æŒ Azure éƒ¨ç½²
   - ç¯å¢ƒå˜é‡é…ç½®

3. **æ·»åŠ  Google Gemini æ”¯æŒ**
   - é›†æˆ Google AI SDK
   - æ”¯æŒ Gemini Pro

### ğŸŸ¢ ä½ä¼˜å…ˆçº§

4. **å…¶ä»– Provider**
   - Cohere
   - Hugging Face
   - æœ¬åœ°æ¨¡å‹ (Ollama, LM Studio)

---

## ğŸ“ å®ç°æ­¥éª¤

### Step 1: å®‰è£…ä¾èµ–

```bash
# æ·»åŠ åˆ° pyproject.toml
uv add anthropic
```

### Step 2: åˆ›å»º AnthropicModel

```python
# agio/models/anthropic.py
# å‚è€ƒ openai.py çš„å®ç°ç»“æ„
```

### Step 3: æ›´æ–° Factory

```python
# agio/registry/factory.py
provider_map = {
    "openai": "agio.models.openai.OpenAIModel",
    "deepseek": "agio.models.deepseek.DeepSeekModel",
    "anthropic": "agio.models.anthropic.AnthropicModel",  # æ–°å¢
}
```

### Step 4: æµ‹è¯•

```python
from agio.registry import load_from_config

load_from_config("./configs")
registry = get_registry()

# æµ‹è¯• Claude åŠ è½½
claude = registry.get("claude")
assert claude is not None
```

---

## ğŸ“Š å½“å‰ Model æ”¯æŒçŸ©é˜µ

| Provider | å®ç°çŠ¶æ€ | é…ç½®æ–‡ä»¶ | Factory æ”¯æŒ | å¯ç”¨æ€§ |
|----------|---------|---------|-------------|--------|
| OpenAI | âœ… å®Œæ•´ | âœ… æ˜¯ | âœ… æ˜¯ | âœ… å¯ç”¨ |
| DeepSeek | âœ… å®Œæ•´ | âœ… æ˜¯ | âœ… æ˜¯ | âœ… å¯ç”¨ |
| Anthropic | âŒ ç¼ºå¤± | âœ… æ˜¯ | âŒ å¦ | âŒ ä¸å¯ç”¨ |
| Google | âŒ ç¼ºå¤± | âŒ å¦ | âŒ å¦ | âŒ ä¸å¯ç”¨ |
| Azure | âŒ ç¼ºå¤± | âŒ å¦ | âŒ å¦ | âŒ ä¸å¯ç”¨ |
| Cohere | âŒ ç¼ºå¤± | âŒ å¦ | âŒ å¦ | âŒ ä¸å¯ç”¨ |
