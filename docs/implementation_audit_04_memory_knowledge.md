# å®ç°å®¡è®¡ - Memory & Knowledge

## 3. Memory å®ç°

**å®Œæˆåº¦**: âŒ 20%  
**çŠ¶æ€**: ğŸ”´ ä¸¥é‡ç¼ºå¤±

---

### âœ… å·²å®ç°åŠŸèƒ½

#### 3.1 Simple Memory

**ä½ç½®**: `agio/memory/simple.py`  
**åŠŸèƒ½å®Œæ•´åº¦**: âœ… 60%

**å·²å®ç°**:
- âœ… åŸºç¡€çš„æ¶ˆæ¯åˆ—è¡¨å­˜å‚¨
- âœ… æœ€å¤§é•¿åº¦é™åˆ¶
- âœ… æ·»åŠ /è·å–/æ¸…é™¤æ¶ˆæ¯

**ä»£ç **:
```python
class SimpleMemory(BaseMemory):
    """Simple in-memory message storage"""
    
    def __init__(self, max_messages: int = 100):
        self.max_messages = max_messages
        self.messages: list[dict] = []
    
    def add_message(self, role: str, content: str):
        self.messages.append({"role": role, "content": content})
        if len(self.messages) > self.max_messages:
            self.messages.pop(0)
```

**ç¼ºé™·**:
- âŒ æ— æŒä¹…åŒ–
- âŒ æ— ä¼šè¯éš”ç¦»
- âŒ æ— è¯­ä¹‰æœç´¢

---

### âŒ ç¼ºå¤±åŠŸèƒ½

#### 3.2 ConversationMemory ç”Ÿäº§å®ç°

**å½“å‰çŠ¶æ€**: ä»…æœ‰ Mock å®ç°  
**ä½ç½®**: `agio/memory/example/__init__.py`

**é…ç½®æ–‡ä»¶**:
```yaml
# configs/memory/conversation_memory.yaml
type: memory
name: conversation_memory
class_path: agio.memory.example.ConversationMemory  # âŒ Mock
max_history_length: 20
max_tokens: 4000
```

**é—®é¢˜**:
- âŒ ä»…è¿”å› Mock æ•°æ®
- âŒ æ— å®é™…å­˜å‚¨
- âŒ æ—  token è®¡æ•°

**éœ€è¦å®ç°**:
```python
# agio/memory/conversation.py

class ConversationMemory(BaseMemory):
    """Production conversation memory"""
    
    def __init__(
        self,
        max_history_length: int = 20,
        max_tokens: int = 4000,
        storage_backend: str = "redis"  # æˆ– "postgres"
    ):
        self.max_history_length = max_history_length
        self.max_tokens = max_tokens
        self.storage = self._init_storage(storage_backend)
    
    def add_message(self, session_id: str, role: str, content: str):
        # å®é™…å­˜å‚¨åˆ° Redis/Database
        # è®¡ç®— tokens
        # è‡ªåŠ¨ä¿®å‰ªå†å²
        pass
    
    def get_messages(self, session_id: str) -> list[dict]:
        # ä»å­˜å‚¨è¯»å–
        # æŒ‰ token é™åˆ¶è¿”å›
        pass
```

---

#### 3.3 SemanticMemory å®ç°

**å½“å‰çŠ¶æ€**: å®Œå…¨æ˜¯ Mock  
**ä½ç½®**: `agio/memory/example/__init__.py`

**é…ç½®æ–‡ä»¶**:
```yaml
# configs/memory/semantic_memory.yaml
type: memory
name: semantic_memory
class_path: agio.memory.example.SemanticMemory  # âŒ Mock
vector_store: chroma
embedding_model: text-embedding-ada-002  # âŒ æœªé›†æˆ
params:
  collection_name: agent_memory
  similarity_threshold: 0.75
```

**é—®é¢˜**:
- âŒ æ— å‘é‡åµŒå…¥
- âŒ æ— å‘é‡æ•°æ®åº“é›†æˆ
- âŒ æ— è¯­ä¹‰æœç´¢

**éœ€è¦å®ç°**:
1. **Embedding API é›†æˆ**
   ```python
   from openai import AsyncOpenAI
   
   async def get_embedding(text: str) -> list[float]:
       client = AsyncOpenAI()
       response = await client.embeddings.create(
           model="text-embedding-ada-002",
           input=text
       )
       return response.data[0].embedding
   ```

2. **å‘é‡æ•°æ®åº“é›†æˆ**
   - Chroma
   - Pinecone
   - Weaviate
   - Qdrant

3. **è¯­ä¹‰æœç´¢**
   ```python
   async def search_similar(
       self,
       query: str,
       top_k: int = 5
   ) -> list[dict]:
       # 1. è·å– query embedding
       query_embedding = await get_embedding(query)
       
       # 2. å‘é‡æœç´¢
       results = self.vector_store.search(
           query_embedding,
           top_k=top_k
       )
       
       return results
   ```

---

#### 3.4 Redis/Database æŒä¹…åŒ–

**çŠ¶æ€**: âŒ æœªå®ç°

**éœ€æ±‚**:
- Redis é›†æˆ - å¿«é€Ÿè®¿é—®
- PostgreSQL é›†æˆ - æŒä¹…åŒ–å­˜å‚¨
- ä¼šè¯ç®¡ç†
- è‡ªåŠ¨è¿‡æœŸ

**å®ç°ç¤ºä¾‹**:
```python
# agio/memory/storage/redis.py

import redis.asyncio as redis

class RedisMemoryStorage:
    def __init__(self, redis_url: str):
        self.redis = redis.from_url(redis_url)
    
    async def save_message(
        self,
        session_id: str,
        message: dict,
        ttl: int = 3600
    ):
        key = f"session:{session_id}:messages"
        await self.redis.lpush(key, json.dumps(message))
        await self.redis.expire(key, ttl)
    
    async def get_messages(
        self,
        session_id: str,
        limit: int = 20
    ) -> list[dict]:
        key = f"session:{session_id}:messages"
        messages = await self.redis.lrange(key, 0, limit - 1)
        return [json.loads(m) for m in messages]
```

---

## 4. Knowledge å®ç°

**å®Œæˆåº¦**: âŒ 20%  
**çŠ¶æ€**: ğŸ”´ ä¸¥é‡ç¼ºå¤±

---

### âœ… å·²å®ç°åŠŸèƒ½

#### 4.1 Chroma Knowledge (éƒ¨åˆ†)

**ä½ç½®**: `agio/knowledge/chroma.py`  
**åŠŸèƒ½å®Œæ•´åº¦**: âš ï¸ 30%

**å·²å®ç°**:
- âœ… åŸºç¡€çš„ Chroma é›†æˆæ¡†æ¶
- âœ… Collection åˆ›å»º

**ç¼ºå¤±**:
- âŒ Embedding é›†æˆ
- âŒ æ–‡æ¡£åŠ è½½
- âŒ åˆ†å—é€»è¾‘
- âŒ æ£€ç´¢åŠŸèƒ½

---

### âŒ ç¼ºå¤±åŠŸèƒ½

#### 4.2 VectorKnowledge ç”Ÿäº§å®ç°

**å½“å‰çŠ¶æ€**: ä»…æœ‰ Mock  
**ä½ç½®**: `agio/knowledge/example/__init__.py`

**é…ç½®æ–‡ä»¶**:
```yaml
# configs/knowledge/product_docs.yaml
type: knowledge
name: product_docs
class_path: agio.knowledge.example.VectorKnowledge  # âŒ Mock
vector_store: chroma
embedding_model: text-embedding-ada-002  # âŒ æœªé›†æˆ
params:
  collection_name: product_docs
  chunk_size: 1000
  chunk_overlap: 200
  data_path: ./data/product_docs
```

**é—®é¢˜**:
- âŒ æ— å®é™…æ–‡æ¡£åŠ è½½
- âŒ æ— å‘é‡åŒ–
- âŒ æ— æ£€ç´¢åŠŸèƒ½

---

#### 4.3 Embedding Model é›†æˆ

**çŠ¶æ€**: âŒ å®Œå…¨ç¼ºå¤±

**éœ€è¦å®ç°**:

1. **OpenAI Embeddings**
   ```python
   # agio/knowledge/embeddings/openai.py
   
   class OpenAIEmbedding:
       def __init__(self, model: str = "text-embedding-ada-002"):
           self.client = AsyncOpenAI()
           self.model = model
       
       async def embed_text(self, text: str) -> list[float]:
           response = await self.client.embeddings.create(
               model=self.model,
               input=text
           )
           return response.data[0].embedding
       
       async def embed_batch(
           self,
           texts: list[str]
       ) -> list[list[float]]:
           response = await self.client.embeddings.create(
               model=self.model,
               input=texts
           )
           return [d.embedding for d in response.data]
   ```

2. **Sentence Transformers**
   ```python
   # agio/knowledge/embeddings/sentence_transformers.py
   
   from sentence_transformers import SentenceTransformer
   
   class STEmbedding:
       def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
           self.model = SentenceTransformer(model_name)
       
       def embed_text(self, text: str) -> list[float]:
           return self.model.encode(text).tolist()
   ```

---

#### 4.4 æ–‡æ¡£åŠ è½½å’Œåˆ†å—

**çŠ¶æ€**: âŒ æœªå®ç°

**éœ€è¦åŠŸèƒ½**:

1. **æ–‡ä»¶è¯»å–**
   - PDF
   - TXT
   - Markdown
   - DOCX
   - HTML

2. **æ™ºèƒ½åˆ†å—**
   ```python
   # agio/knowledge/chunking.py
   
   class TextChunker:
       def __init__(
           self,
           chunk_size: int = 1000,
           chunk_overlap: int = 200
       ):
           self.chunk_size = chunk_size
           self.chunk_overlap = chunk_overlap
       
       def chunk_text(self, text: str) -> list[str]:
           # æŒ‰å¥å­åˆ†å—
           # ä¿æŒè¯­ä¹‰å®Œæ•´æ€§
           # å¤„ç†é‡å 
           pass
   ```

3. **å…ƒæ•°æ®æå–**
   - æ–‡ä»¶å
   - åˆ›å»ºæ—¶é—´
   - ä½œè€…
   - æ ‡ç­¾

---

#### 4.5 å‘é‡æ£€ç´¢

**çŠ¶æ€**: âŒ Mock å®ç°

**éœ€è¦å®ç°**:
```python
# agio/knowledge/vector_knowledge.py

class VectorKnowledge:
    def __init__(
        self,
        vector_store: str,
        embedding_model: str,
        params: dict
    ):
        self.embedding = self._init_embedding(embedding_model)
        self.vector_store = self._init_vector_store(vector_store)
        self.chunk_size = params.get("chunk_size", 1000)
        self.chunk_overlap = params.get("chunk_overlap", 200)
    
    async def add_documents(
        self,
        documents: list[str],
        metadatas: list[dict] | None = None
    ):
        # 1. åˆ†å—
        chunks = self._chunk_documents(documents)
        
        # 2. ç”Ÿæˆ embeddings
        embeddings = await self.embedding.embed_batch(chunks)
        
        # 3. å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        await self.vector_store.add(
            texts=chunks,
            embeddings=embeddings,
            metadatas=metadatas
        )
    
    async def search(
        self,
        query: str,
        top_k: int = 5,
        threshold: float = 0.7
    ) -> list[dict]:
        # 1. Query embedding
        query_embedding = await self.embedding.embed_text(query)
        
        # 2. å‘é‡æœç´¢
        results = await self.vector_store.search(
            query_embedding,
            top_k=top_k
        )
        
        # 3. è¿‡æ»¤é˜ˆå€¼
        return [r for r in results if r["score"] >= threshold]
```

---

## ğŸ¯ ä¼˜å…ˆçº§å»ºè®®

### ğŸ”´ é«˜ä¼˜å…ˆçº§

1. **å®ç° ConversationMemory**
   - Redis æŒä¹…åŒ–
   - Token è®¡æ•°
   - ä¼šè¯ç®¡ç†

2. **å®ç° Embedding é›†æˆ**
   - OpenAI Embeddings API
   - é…ç½®åŒ– embedding model

3. **å®ç° VectorKnowledge**
   - æ–‡æ¡£åŠ è½½
   - åˆ†å—é€»è¾‘
   - å‘é‡æ£€ç´¢

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§

4. **å®Œå–„ Chroma é›†æˆ**
   - å®Œæ•´çš„ CRUD æ“ä½œ
   - å…ƒæ•°æ®è¿‡æ»¤

5. **å®ç° SemanticMemory**
   - å‘é‡åŒ–æ¶ˆæ¯
   - è¯­ä¹‰æœç´¢

### ğŸŸ¢ ä½ä¼˜å…ˆçº§

6. **å…¶ä»–å‘é‡æ•°æ®åº“**
   - Pinecone
   - Weaviate
   - Qdrant

7. **é«˜çº§æ–‡æ¡£å¤„ç†**
   - PDF è§£æ
   - è¡¨æ ¼æå–
   - å›¾ç‰‡ OCR
